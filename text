import os

from lib.exceptions import exception_handler
from lib.sharepoint_apis import Sharepoint
from lib.utils import (get_required_attr, invoke_stepfunction, s3_get_object, s3_list_contents, extract_software_name,
                        email_validator)
from lib.utils import S3_VIRTUAL_LIBRARY_FOLDER_NAME, SUPPORT_EMAILS
from lib.exceptions import ApplicationError

FILE_TRANSFER_SIZE_LIMIT = 10 * 1024 * 1024  # 10 MB


@exception_handler
def lambda_handler(event, context, logger):
    # Extract required event attributes
    attr_values = get_required_attr(event, 'request_num', 'requested_for', 'requested_by', 'bucket_key')
    request_num = attr_values['request_num']
    requested_for = attr_values['requested_for']
    requested_by = attr_values['requested_by']
    support_emails = os.getenv(SUPPORT_EMAILS, '').split(',')

    recipients = attr_values['requested_for'].split(",")
    bucket_key = attr_values['bucket_key']
    bucket_name = os.environ['LIBRARY_BUCKET_NAME']
    bucket_key, software_name = extract_software_name(request_num=request_num, bucket_key=bucket_key)

    # List S3 objects under the given prefix
    objects, total_files_count = s3_list_contents(logger=logger, bucket_name=bucket_name, object_key=bucket_key)
    # Fail if no objects/folders exists in S3
    if len(objects) == 0:
        raise ApplicationError("No data found in Virtual Library.")

    # SharePoint
    sharepoint = Sharepoint(logger=logger)
    # Create Sharepoint folder request_num
    sharepoint.create_folder(folder_name=request_num)
    # Create Folder with Software_name
    sharepoint.create_subfolder(existing_folder=request_num, folder_name=software_name)
    # Sharepoint create/upload files logic
    invoke_sf_flow = False
    # Lambda should only process single files. additional folders should be handled by step function. -- Design
    if len(objects) == 1 and total_files_count == 1:
        for obj in objects:
            key = obj['Key']
            if key.startswith(S3_VIRTUAL_LIBRARY_FOLDER_NAME):
                key = key.removeprefix(S3_VIRTUAL_LIBRARY_FOLDER_NAME + "/")
            if key.startswith(software_name):
                key = key.removeprefix(software_name + "/")
            # Extract the filename
            file_name = os.path.basename(key)
            # Extract the directory path
            directory_path = os.path.dirname(key)
            path_ids = [request_num, software_name]
            if directory_path:
                # Create folders even if file doesn't exists
                sharepoint.create_subfolder(existing_folder=request_num + "/" + software_name,
                                            folder_name=directory_path)
                path_ids.append(directory_path)
            # Upload file if exists and meet requirement.
            if file_name and 'Size' in obj and obj['Size'] <= FILE_TRANSFER_SIZE_LIMIT:

                filedata = s3_get_object(logger=logger, bucket_name=bucket_name, file_key=obj['Key'])
                sharepoint.upload_file(path_ids=path_ids, file_name=file_name,
                                       data=filedata)
            else:
                invoke_sf_flow = True
    else:
        invoke_sf_flow = True
    if invoke_sf_flow:
        logger.info(f"Processing this request in Step function: {len(objects)} number of files: {total_files_count}")
        sf_input = {
            "request_num": request_num,
            "bucket_key": bucket_key,
            "requested_for": requested_for,
            "requested_by": requested_by,
            "library_bucket_name": bucket_name
        }
        logger.info("invoking step function")
        invoke_stepfunction(logger=logger, request_num=request_num, sf_input=sf_input)
    else:
        # Verify Request folder exists
        item_id = sharepoint.get_item_id(folder_name=request_num)
        # Grant READ-ONLY access to requested_by user
        sharepoint.grant_read_access(item_id=item_id, user_email=requested_by)
        # Send Invite
        invite = sharepoint.send_invite(item_id=item_id,
                                        request_number=request_num,
                                        software_title=software_name,
                                        recipients=[email for email in ([requested_for] + support_emails) if
                                                    email_validator(email)],
                                        operation='checkout')
        logger.info(f"Invite response: {invite}")
    sharepoint_url = sharepoint.get_sharepoint_url(folder_name=request_num, operation='checkout')
    return {
        'statusCode': 200,
        'sharepointUrl': sharepoint_url
    }





    def grant_read_access(self, item_id, user_email):
        """
        Grant READ-ONLY access to a drive item for a specific user without sending an invitation email.
        """
        assert_value(item_id, 'Sharepoint item_id cannot be empty.')
        assert_value(user_email, 'User email cannot be empty.')

        url = f"{self.GRAPH_API}/drives/{self.drive_id}/items/{item_id}/invite"

        invite_payload = {
            "recipients": [{"email": user_email}],
            "requireSignIn": True,
            "sendInvitation": False,
            "roles": ["read"]
        }

        response = self.send_api_request(url=url, method="POST", data=invite_payload)
        self.logger.info(f"Granted read access to {user_email} for item {item_id}. Response: {json.dumps(response)}")
        return response
